# Классификация токсичных рецензий исходного кода

## Цель проекта
Сравнение различных подходов машинного обучения для классификации токсичных комментариев в рецензиях исходного кода.

## Данные
- **Общий размер датасета**: 12,844 записей
- **Обучающая выборка**: 10,275 записей
- **Тестовая выборка**: 2,569 записей
- **Распределение классов**:
  - Non-Toxic: 8,282 (80.6%)
  - Toxic: 1,993 (19.4%)

## Методы сравнения

### Классические модели
- **Logistic Regression** с CountVectorizer и TF-IDF
- **Random Forest** с CountVectorizer и TF-IDF
- 10-фолдовая кросс-валидация
- Подбор гиперпараметров

### Трансформер-модели
- **RoBERTa** (base)
- **CodeBERT** (специализированная для исходного кода)

## Результаты

### Сравнение метрик (отсортировано по F1-Score)

| Модель | Accuracy | Precision | Recall | F1-Score |
|--------|----------|-----------|--------|-----------|
| CodeBERT | 0.9171 | 0.9154 | 0.9171 | **0.9121** |
| LR (Count) | 0.8863 | 0.8915 | 0.8863 | 0.8884 |
| RF (Count) | 0.8743 | 0.8779 | 0.8743 | 0.8759 |
| LR (TF-IDF) | 0.8715 | 0.8835 | 0.8715 | 0.8759 |
| RF (TF-IDF) | 0.8704 | 0.8743 | 0.8704 | 0.8721 |
| RoBERTa | 0.8062 | 0.6499 | 0.8062 | 0.7196 |

### Детализация результатов классических моделей

#### CountVectorizer
- **Logistic Regression**:
  - CV F1-score: 0.8855 ± 0.0195
  - Test Accuracy: 0.8863
  - Precision/Recall: 0.94/0.92 (Non-Toxic), 0.69/0.76 (Toxic)

- **Random Forest**:
  - CV F1-score: 0.8793 ± 0.0153
  - Test Accuracy: 0.8743
  - Precision/Recall: 0.93/0.91 (Non-Toxic), 0.66/0.71 (Toxic)

#### TF-IDF Vectorizer
- **Logistic Regression**:
  - CV F1-score: 0.8747 ± 0.0199
  - Test Accuracy: 0.8715

- **Random Forest**:
  - CV F1-score: 0.8699 ± 0.0169
  - Test Accuracy: 0.8704

### Результаты трансформер-моделей

#### CodeBERT
- **Accuracy**: 0.9171
- **F1-Score**: 0.9121
- **Precision/Recall**: 0.92/0.98 (Non-Toxic), 0.89/0.65 (Toxic)
- **Время обучения**: ~3.5 часов

#### RoBERTa
- **Accuracy**: 0.8062
- **F1-Score**: 0.7196
- **Основная проблема**: модель научилась предсказывать только класс Non-Toxic
- **Время обучения**: ~10.8 часов

### Подбор гиперпараметров
- **Лучшие параметры Logistic Regression**: 
  - `{'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}`
  - F1-score: 0.8964

- **Лучшие параметры Random Forest**:
  - `{'max_depth': None, 'min_samples_split': 5, 'n_estimators': 200}`
  - F1-score: 0.8969

## Выводы

### Лучшая модель: CodeBERT
- **F1-Score**: 0.9121
- **Accuracy**: 0.9171
- **Precision**: 0.9154
- **Recall**: 0.9171

### Ключевые наблюдения

1. **CodeBERT показал наилучшие результаты**, что подтверждает эффективность специализированных моделей для работы с кодом
2. **RoBERTa показала неудовлетворительные результаты** - модель не смогла научиться различать токсичные комментарии
3. **Классические модели** демонстрируют стабильные результаты:
   - CountVectorizer немного превосходит TF-IDF
   - Logistic Regression показывает лучшие результаты чем Random Forest
4. **Дисбаланс классов** повлиял на все модели, но CodeBERT лучше справился с minority class
